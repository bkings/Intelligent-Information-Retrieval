[
  {
    "title": "Learning from less: SINDy Surrogates in RL",
    "pub_link": "https://pureportal.coventry.ac.uk/en/publications/learning-from-less-sindy-surrogates-in-rl/",
    "authors": [
      "Aniket Dixit",
      "Muhammad Ibrahim Khan",
      "Faizan Ahmed",
      "James Brusey"
    ],
    "author_profiles": [
      "https://pureportal.coventry.ac.uk/en/persons/aniket-dixit/",
      "https://pureportal.coventry.ac.uk/en/persons/muhammad-ibrahim-khan/",
      "https://pureportal.coventry.ac.uk/en/persons/faizan-ahmed/",
      "https://pureportal.coventry.ac.uk/en/persons/james-brusey/"
    ],
    "year": "26 Apr 2025",
    "abstract": "This paper presents a method to create simpler versions of reinforcement learning (RL) environments using the Sparse Identification of Nonlinear Dynamics (SINDy) algorithm. The method was tested in OpenAI Gym's Mountain Car and Lunar Lander environments. Results show that these SINDy-based models can closely match the real environment's behavior while cutting down computational cost by 20\u201335%. With just 75 data points for Mountain Car and 1000 for Lunar Lander, the models achieved over 0.997 state-wise correlation, with very low prediction errors (as low as 3.11 \u00d7 10\u207b\u2076 for Mountain Car velocity and 1.42 \u00d7 10\u207b\u2076 for Lunar Lander position). RL agents trained in these simplified environments needed fewer steps to learn (65,075 vs. 100,000 for Mountain Car and 801,000 vs. 1,000,000 for Lunar Lander) and performed similarly to those trained in the full environments. This work offers a fast and accurate way to create interpretable models for use in model-based RL.",
    "doi": "https://doi.org/10.48550/arXiv.2504.18113",
    "pdf_link": "",
    "content": "learning from less sindy surrogates in rl aniket dixit muhammad ibrahim khan faizan ahmed james brusey 26 apr 2025 this paper presents a method to create simpler versions of reinforcement learning rl environments using the sparse identification of nonlinear dynamics sindy algorithm the method was tested in openai gym s mountain car and lunar lander environments results show that these sindy based models can closely match the real environment s behavior while cutting down computational cost by 20 35 with just 75 data points for mountain car and 1000 for lunar lander the models achieved over 0 997 state wise correlation with very low prediction errors as low as 3 11 10 \u2076 for mountain car velocity and 1 42 10 \u2076 for lunar lander position rl agents trained in these simplified environments needed fewer steps to learn 65 075 vs 100 000 for mountain car and 801 000 vs 1 000 000 for lunar lander and performed similarly to those trained in the full environments this work offers a fast and accurate way to create interpretable models for use in model based rl"
  }
]